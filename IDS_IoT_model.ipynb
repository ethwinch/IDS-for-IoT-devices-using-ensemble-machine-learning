{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb8b54e-fd56-40a8-bab0-d0a8748b46b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import glob\n",
    "import os\n",
    "#merge all files starting in \"part\" & ending in \"csv\" inside the selected path\n",
    "all_files = os.path.join(\"CIC-IoT-2023/\",\"part*.csv\")\n",
    "#list of all merged files\n",
    "joined_files = glob.glob(all_files)\n",
    "#merged files\n",
    "df = pd.concat(map(pd.read_csv, joined_files), ignore_index=True)\n",
    "# pd.read_csv(joined_files, chunksize=1000)\n",
    "#df = pd.read_csv(df, chunksize=1000)\n",
    "\n",
    "df_test = df.head(5)\n",
    "df_test\n",
    "\n",
    "# df = pd.read_csv('part-00000-363d1ba3-8ab5-4f96-bc25-4d5862db7cb9-c000.csv')\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aba6727-8c04-4d05-87b8-d3494726aab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARE DATA\n",
    "#create input data\n",
    "X = df.drop(columns=['label'])\n",
    "\n",
    "#create output (prediction) data\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed230ec7-c42d-4de1-b9fb-9a70b71bd3a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data - 80% training, 20% testing\n",
    "# training input data, testing input data, training output data, testing output data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76170ab4-e59e-4cff-9b18-da4a337e340b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Classifier Accuracy:  0.08728985931289034\n",
      "Classification Report:                          precision    recall  f1-score   support\n",
      "\n",
      "       Backdoor_Malware       0.00      0.00      0.00       623\n",
      "          BenignTraffic       0.02      0.02      0.02    219458\n",
      "       BrowserHijacking       0.00      0.00      0.00      1201\n",
      "       CommandInjection       0.00      0.00      0.00      1049\n",
      " DDoS-ACK_Fragmentation       0.01      0.01      0.01     56930\n",
      "        DDoS-HTTP_Flood       0.00      0.00      0.00      5656\n",
      "        DDoS-ICMP_Flood       0.15      0.15      0.15   1441384\n",
      "DDoS-ICMP_Fragmentation       0.01      0.01      0.01     90474\n",
      "      DDoS-PSHACK_Flood       0.09      0.09      0.09    819229\n",
      "       DDoS-RSTFINFlood       0.09      0.09      0.09    808828\n",
      "         DDoS-SYN_Flood       0.09      0.09      0.09    812155\n",
      "         DDoS-SlowLoris       0.00      0.00      0.00      4684\n",
      "DDoS-SynonymousIP_Flood       0.08      0.08      0.08    719249\n",
      "         DDoS-TCP_Flood       0.10      0.10      0.10    898883\n",
      "         DDoS-UDP_Flood       0.12      0.12      0.12   1082643\n",
      " DDoS-UDP_Fragmentation       0.01      0.01      0.01     57181\n",
      "           DNS_Spoofing       0.00      0.00      0.00     36005\n",
      "   DictionaryBruteForce       0.00      0.00      0.00      2541\n",
      "         DoS-HTTP_Flood       0.00      0.00      0.00     14430\n",
      "          DoS-SYN_Flood       0.04      0.04      0.04    405842\n",
      "          DoS-TCP_Flood       0.06      0.06      0.06    535580\n",
      "          DoS-UDP_Flood       0.07      0.07      0.07    662273\n",
      "       MITM-ArpSpoofing       0.01      0.01      0.01     61142\n",
      "     Mirai-greeth_flood       0.02      0.02      0.02    198338\n",
      "      Mirai-greip_flood       0.02      0.02      0.02    149987\n",
      "         Mirai-udpplain       0.02      0.02      0.02    178440\n",
      "    Recon-HostDiscovery       0.00      0.00      0.00     26847\n",
      "           Recon-OSScan       0.00      0.00      0.00     19759\n",
      "        Recon-PingSweep       0.00      0.00      0.00       472\n",
      "         Recon-PortScan       0.00      0.00      0.00     16571\n",
      "           SqlInjection       0.00      0.00      0.00      1011\n",
      "       Uploading_Attack       0.00      0.00      0.00       250\n",
      "      VulnerabilityScan       0.00      0.00      0.00      7443\n",
      "                    XSS       0.00      0.00      0.00       758\n",
      "\n",
      "               accuracy                           0.09   9337316\n",
      "              macro avg       0.03      0.03      0.03   9337316\n",
      "           weighted avg       0.09      0.09      0.09   9337316\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Baseline Random Classifier\n",
    "dummy_classifier = DummyClassifier(strategy='stratified', random_state=42)\n",
    "# Fit baseline classifier on training data\n",
    "dummy_classifier.fit(X_train, y_train)\n",
    "# Predictions from test data\n",
    "y_pred_dummy = dummy_classifier.predict(X_test)\n",
    "\n",
    "dummy_acc = accuracy_score(y_test, y_pred_dummy)\n",
    "report = classification_report(y_test, y_pred_dummy)\n",
    "\n",
    "print(\"Baseline Classifier Accuracy: \", dummy_acc)\n",
    "print(\"Classification Report:\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5820235-b404-48d2-8e5b-4013173c9941",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESHAPE DATA from 3d to 2d\n",
    "#nx, ny = X_train.shape\n",
    "#d2_train_dataset = X_train.values.reshape(nx,ny)\n",
    "#d2_train_dataset\n",
    "models = {}\n",
    "results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e215d70-0da5-4603-bd60-2de48b0fb1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# models = [\n",
    "#     ('dt', tree.DecisionTreeClassifier()),\n",
    "#     ('rf', RandomForestClassifier())\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b52d5759-bf02-494e-90de-6765d3c042d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(name, model, X_train, y_train, X_test, y_test):\n",
    "    # Train model\n",
    "    model.fit(X_train, y_train)\n",
    "    # Predictions\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_probability = model.predict_proba(X_test)[:,1]\n",
    "\n",
    "    # Scoring\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    roc = roc_auc_score(y_test, y_pred_probability)\n",
    "\n",
    "    print(f\"\\n{name} Results: \")\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(f\"F1: {f1:.4f}\")\n",
    "    print(f\"ROC-AUC: {roc:.4f}\")\n",
    "    print(f\"\\nClassification Report: \")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "\n",
    "    return{\n",
    "        'model': model,\n",
    "        'accuracy': acc,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc,\n",
    "        'y_pred': y_pred,\n",
    "        'y_pred_probability': y_pred_probability\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b9516f4-e284-4988-b816-724d4497186a",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 6.40 GiB for an array with shape (37349263, 46) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mMemoryError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_16572\\1651207892.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m rf_model = RandomForestClassifier(\n\u001b[32m      2\u001b[39m     n_estimators=\u001b[32m500\u001b[39m,\n\u001b[32m      3\u001b[39m     max_depth=\u001b[32m15\u001b[39m\n\u001b[32m      4\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m results[\u001b[33m'RandomForest'\u001b[39m] = evaluate_model(\u001b[33m'RandomForest'\u001b[39m, rf_model, X_train, y_train, X_test, y_test)\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_16572\\832126840.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(name, model, X_train, y_train, X_test, y_test)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m evaluate_model(name, model, X_train, y_train, X_test, y_test):\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Train model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     model.fit(X_train, y_train)\n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Predictions\u001b[39;00m\n\u001b[32m      5\u001b[39m     y_pred = model.predict(X_test)\n\u001b[32m      6\u001b[39m     y_pred_probability = model.predict_proba(X_test)[:,\u001b[32m1\u001b[39m]\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1361\u001b[39m                 skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m                     prefer_skip_nested_validation \u001b[38;5;28;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m                 )\n\u001b[32m   1364\u001b[39m             ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m                 \u001b[38;5;28;01mreturn\u001b[39;00m fit_method(estimator, *args, **kwargs)\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m    355\u001b[39m         \u001b[38;5;66;03m# Validate or convert input data\u001b[39;00m\n\u001b[32m    356\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m issparse(y):\n\u001b[32m    357\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m ValueError(\u001b[33m\"sparse multilabel-indicator for y is not supported.\"\u001b[39m)\n\u001b[32m    358\u001b[39m \n\u001b[32m--> \u001b[39m\u001b[32m359\u001b[39m         X, y = validate_data(\n\u001b[32m    360\u001b[39m             self,\n\u001b[32m    361\u001b[39m             X,\n\u001b[32m    362\u001b[39m             y,\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2967\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"estimator\"\u001b[39m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01min\u001b[39;00m check_y_params:\n\u001b[32m   2968\u001b[39m                 check_y_params = {**default_check_params, **check_y_params}\n\u001b[32m   2969\u001b[39m             y = check_array(y, input_name=\u001b[33m\"y\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m             X, y = check_X_y(X, y, **check_params)\n\u001b[32m   2972\u001b[39m         out = X, y\n\u001b[32m   2973\u001b[39m \n\u001b[32m   2974\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m no_val_X \u001b[38;5;28;01mand\u001b[39;00m check_params.get(\u001b[33m\"ensure_2d\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1364\u001b[39m         )\n\u001b[32m   1365\u001b[39m \n\u001b[32m   1366\u001b[39m     ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m   1367\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m     X = check_array(\n\u001b[32m   1369\u001b[39m         X,\n\u001b[32m   1370\u001b[39m         accept_sparse=accept_sparse,\n\u001b[32m   1371\u001b[39m         accept_large_sparse=accept_large_sparse,\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1050\u001b[39m                         )\n\u001b[32m   1051\u001b[39m                     array = xp.astype(array, dtype, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m   1052\u001b[39m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1053\u001b[39m                     array = _asarray_with_order(array, order=order, dtype=dtype, xp=xp)\n\u001b[32m-> \u001b[39m\u001b[32m1054\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m ComplexWarning \u001b[38;5;28;01mas\u001b[39;00m complex_warning:\n\u001b[32m   1055\u001b[39m                 raise ValueError(\n\u001b[32m   1056\u001b[39m                     \u001b[33m\"Complex data not supported\\n{}\\n\"\u001b[39m.format(array)\n\u001b[32m   1057\u001b[39m                 ) \u001b[38;5;28;01mfrom\u001b[39;00m complex_warning\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\_array_api.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(array, dtype, order, copy, xp, device)\u001b[39m\n\u001b[32m    753\u001b[39m         \u001b[38;5;66;03m# Use NumPy API to support order\u001b[39;00m\n\u001b[32m    754\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m    755\u001b[39m             array = numpy.array(array, order=order, dtype=dtype)\n\u001b[32m    756\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m757\u001b[39m             array = numpy.asarray(array, order=order, dtype=dtype)\n\u001b[32m    758\u001b[39m \n\u001b[32m    759\u001b[39m         \u001b[38;5;66;03m# At this point array is a NumPy ndarray. We convert it to an array\u001b[39;00m\n\u001b[32m    760\u001b[39m         \u001b[38;5;66;03m# container that is consistent with the input's namespace.\u001b[39;00m\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, dtype, copy)\u001b[39m\n\u001b[32m   2167\u001b[39m             )\n\u001b[32m   2168\u001b[39m         values = self._values\n\u001b[32m   2169\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2170\u001b[39m             \u001b[38;5;66;03m# Note: branch avoids `copy=None` for NumPy 1.x support\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2171\u001b[39m             arr = np.asarray(values, dtype=dtype)\n\u001b[32m   2172\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2173\u001b[39m             arr = np.array(values, dtype=dtype, copy=copy)\n\u001b[32m   2174\u001b[39m \n",
      "\u001b[31mMemoryError\u001b[39m: Unable to allocate 6.40 GiB for an array with shape (37349263, 46) and data type float32"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=500,\n",
    "    max_depth=15\n",
    ")\n",
    "results['RandomForest'] = evaluate_model('RandomForest', rf_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d62d9b3a-e317-47d8-b3dc-b39d92636fbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_model = tree.DecisionTree()\n",
    "results['DecisionTree'] = evaluate_model('DecisionTree', dt_model, X_train, y_train, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c63969-b993-4504-89d5-d46ffed6c7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Model Comparison\")\n",
    "print(\"-\"*40)\n",
    "\n",
    "comparison = pd.df({\n",
    "    'Model': list(results.keys()),\n",
    "    'Accuracy': [results[m]['accuracy'] for m in results],\n",
    "    'F1': [results[m]['f1_score'] for m in results],\n",
    "    'ROC-AUC': [results[m]['roc_auc'] for m in results]\n",
    "})\n",
    "\n",
    "#comparison = comparison.sort_values('F1', ascending=False)\n",
    "print('\\n', comparison.to_string(index=False))\n",
    "\n",
    "# Best model according to F1 score\n",
    "best_model_name = comparison.iloc[0]['Model']\n",
    "best_model_result = results[best_model_name]\n",
    "best_model = best_model_result['model']\n",
    "\n",
    "print(f\"\\nBest Model: {best_model_name}\")\n",
    "print(f\"Accuracy: {best_model_result['accuracy']:.4f}\")\n",
    "print(f\"F1: {best_model_result['f1_score']:.4f}\")\n",
    "print(f\"ROC-AUC: {best_model_result['roc_auc']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f340e4f-2531-43e4-81fc-859c6e8ca065",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VOTING CLASSIFIER\n",
    "vote_hard = VotingClassifier(estimators=models, voting='hard')\n",
    "vote_hard.fit(X_train, y_train)\n",
    "\n",
    "# PREDICT\n",
    "y_pred = vote_hard.predict(X_test)\n",
    "\n",
    "#dt = tree.DecisionTreeClassifier()\n",
    "#rf = RandomForestClassifier()\n",
    "\n",
    "#dt.fit(X_train, y_train, sample_weight=None)\n",
    "#rf.fit(X_train, y_train, sample_weight=None)\n",
    "\n",
    "# Make dt PERSISTANT\n",
    "#store TRAINED dt in file called IDS_IoT.joblib\n",
    "#joblib.dump(dt, 'IDS_IoT.joblib')\n",
    "#load trained dt from file\n",
    "#dt = joblib.load('IDS_IoT.joblib')\n",
    "\n",
    "#enter data you want a prediction for\n",
    "#rf_predictions = rf.predict(X_test)\n",
    "#dt_predictions = dt.predict(X_test)\n",
    "# rf_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c37148f-0615-4897-bd7c-0ec65dc7a5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCORING\n",
    "# accur_score = accuracy_score(y_test, y_pred)\n",
    "# print(\"Hard Voting Accuracy: \", accur_score)\n",
    "\n",
    "# prec_score = precision_score(y_test, y_pred, average='weighted') # \"ill-defined\" Warning\n",
    "# print(\"Precision Score: \", prec_score)\n",
    "\n",
    "# recall = recall_score(y_test, y_pred, average='weighted')\n",
    "# print(\"Recall Score: \", recall)\n",
    "\n",
    "# f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "# print(\"F1 Score: \", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0cfb3e-7bcd-4c06-a954-c287806b72e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SCORING\n",
    "# rf_accur_score = accuracy_score(y_test, rf_predictions) #returns # from 0-1\n",
    "# dt_accur_score = accuracy_score(y_test, dt_predictions)\n",
    "\n",
    "# rf_precision = precision_score(y_test, rf_predictions, average=None)\n",
    "# dt_precision = precision_score(y_test, dt_predictions, average=None)\n",
    "\n",
    "# rf_recall = recall_score(y_test, rf_predictions, average=None)\n",
    "# dt_recall = recall_score(y_test, dt_predictions, average=None)\n",
    "\n",
    "# print(\"Random Forest\\nAccuracy: \", rf_accur_score)\n",
    "# print(\"Precision: \", rf_precision)\n",
    "# print(\"Recall: \", rf_recall)\n",
    "# print(\"-----------------------------------------\")\n",
    "# print(\"Decision Tree\\nAccuracy: \", dt_accur_score)\n",
    "# print(\"Precision: \", dt_precision)\n",
    "# print(\"Recall: \", dt_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7341e6c-7cec-4ec2-b902-a5f02fefa2b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8957fd33-b7a5-49dc-8001-b678bac32602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# VISUALIZATIONS\n",
    "#decisionTree, filename, display specified columns & rules, output data in alphabetical order, writes info on graph, round box edges, color boxes\n",
    "#tree.export_graphviz(decisionTree, out_file='IDS_IoT_decisionTree.dot', feature_names=X_test.columns, class_names=sorted(y.unique()), label='all', rounded=True, filled=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5361452-d4d3-47bb-9bd2-a026736b9099",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91d2083-cb6d-4723-8937-a34ea6c60934",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
